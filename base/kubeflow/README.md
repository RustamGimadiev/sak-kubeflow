# Kubeflow AWS deployment

For the initial configuration of Kubeflow, a cloud-agnostic deployment version with custom patches was taken.
All patches designed to work with pre-existing in Kubernetes cluster secrets and configmaps. Terraform generate all requred entities (files, SecretManager parameters, etc) and patches are pointed to them. Generally, patches are written for switching to RDS instance and use AWS IAM user credentials to accessing S3 via Minio Gateway. Also, DEX is configured to work with GitHub OIDC provider.

## Modified resources
**Note**: _the `pre-existing` word mean that all these resources were created by ArgoCD and generated by Terraform_

| Name | Kind | Change description |
| -- | -- | -- |
| cache-server | Deployment | Source of DB access credentials changed to pre-existing secret |
| metadata-grpc-deployment | Deployment | Source of DB access credentials changed to pre-existing secret |
| ml-pipeline-ui | Deployment | Configured to use custom storage bucket name |
| ml-pipeline | Deployment | Source of DB access credentials changed to pre-existing secret. Configured to use custom storage bucket name |
| kubeflow-pipelines-profile-controller | Deployment | Configured to use custom storage bucket name |
| workflow-controller | Deployment | Configured to use pre-existing workflow controller configmap |
| dex | Deployment | Configured to use pre-existing secrets and configmaps with OIDC configuration |
| minio | Deployment | Configured to use custom storage bucket name. Switched to s3 gateway mode |
| authservice | StatefulSet | Configured to use pre-existing secret with OIDC configuration |

## sync.py
This Python script create user specific resources in they own namaspace right after the creation Kubeflow profile and creating user namespace. We customized this script with creation one additional ConfigMap `artifact-repositories`. If any other repository not defined in pipeline body then this configuration would be used as a artifact repository for Argo Workflows.
